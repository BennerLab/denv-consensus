import pandas

sample_df = pandas.read_table("sample_sheet.txt", index_col="sample")


def get_subtype_reference(wildcards):
    paf_df = pandas.read_table(f"contig_assembly/{wildcards.sample}/contigs.paf", header=None)

    # find the most frequent contig match
    main_hit = paf_df.value_counts(5).index[0] # column index 5 is the reference sequence name

    return f"reference/{main_hit}.fasta"

def summarize_contig_paf(filename):
    paf_df = pandas.read_table(filename, header=None)

    # count contig matches to DENV references
    count_df = paf_df.value_counts(5)

    # get most common DENV reference and fraction of total
    common_serotype = count_df.index[0]
    contig_pct = float(count_df.iloc[0] / count_df.sum() * 100)

    # column index 1 is the query (contig) length
    # column index 9 is the number of residue matches
    # column index 10 is the alignment block length
    paf_df_sorted = paf_df.sort_values(1, ascending=False)
    contig_max_length = paf_df_sorted.iloc[0, 1]
    longest_serotype = paf_df_sorted.iloc[0, 5]
    matched_region_pct = float(paf_df_sorted.iloc[0, 9] / paf_df_sorted.iloc[0, 10] * 100)

    return {"Prevailing serotype": common_serotype,
            "Prevailing serotype %": contig_pct,
            "Longest contig": contig_max_length,
            "Longest contig serotype": longest_serotype,
            "Longest contig % identity": matched_region_pct}

rule all:
    input:
        expand("consensus/{sample}.fasta", sample=sample_df.index),
        "denv_report.html"

rule multiqc:
    input:
        expand(["contig_assembly/{sample}/{sample}.log", "align/{sample}.stats", "align/{sample}.covstats",
                "consensus/{sample}.stats", "contig_assembly/summary_mqc.txt", "multiple_alignment/tree_mqc.html"], sample=sample_df.index)
    output:
        "denv_report.html"
    shell:
        "multiqc --force --quiet --clean-up --filename {output} {input}"

rule assembly:
    input:
        r1=lambda x: "reads/" + sample_df.loc[x.sample, "read1"],
        r2=lambda x: "reads/" + sample_df.loc[x.sample, "read2"]
    output:
        "contig_assembly/{sample}/{sample}.contigs.fa"
    threads: 1 # currently fails on Mac if more than one thread is used
    log:
        "contig_assembly/{sample}/{sample}.log"
    shell:
        """
        rm -rf contig_assembly/{wildcards.sample}
        megahit --num-cpu-threads {threads} -1 {input.r1} -2 {input.r2} -o contig_assembly/{wildcards.sample} --out-prefix {wildcards.sample} 2> /dev/null
        """

rule align_contigs:
    input:
        "contig_assembly/{sample}/{sample}.contigs.fa"
    output:
        "contig_assembly/{sample}/contigs.paf"
    params:
        reference="reference/NCBI.fasta"
    log:
        "contig_assembly/{sample}/{sample}.contig_minimap2.log"
    threads: 3
    shell:
        "minimap2 -t {threads} {params.reference} {input} > {output} 2> {log}"

rule report_serotype:
    input:
        expand("contig_assembly/{sample}/contigs.paf", sample=sample_df.index)
    output:
        "contig_assembly/summary_mqc.txt"
    params:
        sample_id=sample_df.index
    run:
        report_header = """# id: "Serotype identification"
# description: "Find most commonly matched serotype among contigs in each sample"
# plot_type: "table"\n"""

        record_dict = {}
        for sample_id, filename in zip(params.sample_id, input):
            record_dict[sample_id] = summarize_contig_paf(filename)

        with open(output[0], 'w') as f:
            f.write(report_header)
            pandas.DataFrame.from_dict(record_dict, orient="index").to_csv(f, index_label="Sample")

rule align_reads:
    input:
        r1=lambda x: "reads/" + sample_df.loc[x.sample, "read1"],
        r2=lambda x: "reads/" + sample_df.loc[x.sample, "read2"],
        contig_alignments="contig_assembly/{sample}/contigs.paf"
    output:
        bam="align/{sample}.bam"
    params:
        reference=get_subtype_reference
    log:
        minimap2="align/{sample}.log",
        stats="align/{sample}.stats",
        coverage="align/{sample}.covstats"
    threads: 3
    shell:
        """
        minimap2 -a -t {threads} {params.reference} {input} 2> {log.minimap2} | samtools view -u | samtools sort -o {output}
        samtools stats {output} > {log.stats}
        samtools coverage {output} > {log.coverage}
        """

rule generate_consensus:
    input:
        alignments="align/{sample}.bam",
        contig_alignments="contig_assembly/{sample}/contigs.paf"
    output:
        vcf="consensus/{sample}.vcf.gz",
        fasta="consensus/{sample}.fasta"
    log:
        "consensus/{sample}.stats"
    params:
        reference=get_subtype_reference,
        sequence_prefix=lambda wildcards: f"{wildcards.sample}-",
        depth=10000,
    shell:
        """
        bcftools mpileup --max-depth {params.depth} --redo-BAQ --output-type u --fasta-ref {params.reference} {input.alignments} | bcftools call --write-index --consensus-caller --variants-only --output-type z --output {output.vcf}
        bcftools consensus {output.vcf} --prefix {params.sequence_prefix} --fasta-ref {params.reference} --output {output.fasta}
        bcftools stats {output.vcf} > {log}
        """

rule multiple_alignment:
    input:
        expand("consensus/{sample}.fasta", sample=sample_df.index)
    output:
        "multiple_alignment/alignment.txt"
    log:
        "multiple_alignment/log"
    shell:
        """
        cat {input} | mafft --auto - > {output} 2> {log}
        """

rule tree:
    input:
        "multiple_alignment/alignment.txt"
    output:
        iqtree="multiple_alignment/alignment.txt.iqtree",
        tree="multiple_alignment/tree_mqc.html"
    shell:
        """
        rm -f multiple_alignment/alignment.txt.ckp.gz
        iqtree --quiet -s {input}
        sed -n '/^MAXIMUM LIKELIHOOD TREE$/,/^ALISIM COMMAND$/{{/^ALISIM COMMAND$/d;p;}}' {output.iqtree} | awk 'BEGIN{{print "<html><body><pre>"}} {{print}} END{{print "</pre></body></html>"}}' > {output.tree}
        """

